{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMNBl08od9s+gNp9uezlkEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/illusoryTwin/InnoML/blob/main/test2/Untitled41.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QwqT4zGUjFwN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values of the images\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "id": "FE7ak06LQds0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "from skimage.util import random_noise\n",
        "import numpy as np\n",
        "\n",
        "# Define the desired height and width for resizing\n",
        "desired_height = 32\n",
        "desired_width = 32\n",
        "\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rescale=1./255,            # Rescale pixel values to [0,1]\n",
        "#     rotation_range=20,         # Rotate images by up to 20 degrees\n",
        "#     width_shift_range=0.1,     # Shift images horizontally by up to 10% of width\n",
        "#     height_shift_range=0.1,    # Shift images vertically by up to 10% of height\n",
        "#     brightness_range=[0.8, 1.2],  # Vary brightness between 0.8 and 1.2\n",
        "#     horizontal_flip=True,      # Flip images horizontally\n",
        "#     vertical_flip=True,        # Flip images vertically\n",
        "#     channel_shift_range=100,   # Shift color channels by up to 100\n",
        "# )\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    shear_range=0.1,  # Shear transformation\n",
        "    rotation_range=15,  # Rotation\n",
        "    # width_shift_range=0.1,  # Width shift\n",
        "    # height_shift_range=0.1,  # Height shift\n",
        "    zoom_range=0.1,  # Zoom\n",
        "    # channel_shift_range=0.1,  # Color filtering\n",
        "    preprocessing_function=lambda x: tf.image.resize(x, [desired_height, desired_width]),\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "# Define a function to add random colorful pixels (noise) to the images\n",
        "def add_colorful_noise(image):\n",
        "    # Generate random noise with the same shape as the input image\n",
        "    noise = np.random.randint(0, 256, image.shape, dtype=np.uint8)\n",
        "    # Add the random noise to the input image\n",
        "    noisy_image = cv2.add(image, noise)\n",
        "    return noisy_image\n",
        "\n",
        "# Define data augmentation parameters with resizing and noise\n",
        "datagen = ImageDataGenerator(\n",
        "    shear_range=0.1,             # Shear transformation\n",
        "    rotation_range=15,           # Rotation\n",
        "    zoom_range=0.1,              # Zoom\n",
        "    preprocessing_function=lambda x: add_colorful_noise(x),  # Add colorful noise\n",
        "    # Add other augmentation parameters as needed\n",
        ")\n",
        "\n",
        "\n",
        "# def apply_augmentation(image):\n",
        "#     # Resize the image\n",
        "#     resized_image = cv2.resize(image, (desired_height, desired_width))\n",
        "#     # Add glitter effect\n",
        "#     glittered_image = add_glitter(resized_image)\n",
        "#     return glittered_image\n",
        "\n",
        "# # Define data augmentation parameters\n",
        "# datagen = ImageDataGenerator(\n",
        "#     shear_range=0.1,  # Shear transformation\n",
        "#     zoom_range=0.1,  # Zoom\n",
        "#     preprocessing_function=apply_augmentation  # Apply resizing and glitter effect\n",
        "# )\n",
        "# def add_glitter(image):\n",
        "#     # Randomly generate glitter spots\n",
        "#     num_glitters = np.random.randint(50, 200)  # Number of glitter spots\n",
        "#     for _ in range(num_glitters):\n",
        "#         # Generate random position and radius for glitter spot\n",
        "#         x = np.random.randint(0, image.shape[1])\n",
        "#         y = np.random.randint(0, image.shape[0])\n",
        "#         radius = np.random.randint(1, 4)\n",
        "#         # Generate random color for glitter spot\n",
        "#         color = (np.random.randint(0, 256), np.random.randint(0, 256), np.random.randint(0, 256))\n",
        "#         # Draw glitter spot with random color\n",
        "#         cv2.circle(image, (x, y), radius, color, -1)\n",
        "#     return image\n",
        "\n",
        "# Define the model architecture\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "quvPOpe4Qg3w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\n",
        "\n",
        "\n",
        "# Train the model with data augmentation\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=256),\n",
        "                    epochs=100,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test loss: {test_loss}, Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uir3uTw7RVMk",
        "outputId": "a5e0360b-122d-42fb-dd05-8e527c29fdfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "196/196 [==============================] - 102s 498ms/step - loss: 1.6979 - accuracy: 0.4472 - val_loss: 3.5312 - val_accuracy: 0.1056 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "196/196 [==============================] - 93s 474ms/step - loss: 1.1206 - accuracy: 0.6128 - val_loss: 2.4077 - val_accuracy: 0.2809 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "196/196 [==============================] - 93s 473ms/step - loss: 0.8923 - accuracy: 0.6885 - val_loss: 0.9630 - val_accuracy: 0.6649 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "196/196 [==============================] - 93s 472ms/step - loss: 0.7545 - accuracy: 0.7349 - val_loss: 0.8452 - val_accuracy: 0.7180 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "196/196 [==============================] - 92s 470ms/step - loss: 0.6760 - accuracy: 0.7650 - val_loss: 0.7477 - val_accuracy: 0.7635 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "196/196 [==============================] - 93s 476ms/step - loss: 0.6037 - accuracy: 0.7883 - val_loss: 0.7007 - val_accuracy: 0.7771 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "196/196 [==============================] - 94s 477ms/step - loss: 0.5525 - accuracy: 0.8084 - val_loss: 0.7331 - val_accuracy: 0.7605 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "196/196 [==============================] - 94s 479ms/step - loss: 0.5163 - accuracy: 0.8208 - val_loss: 0.7204 - val_accuracy: 0.7749 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "196/196 [==============================] - 92s 471ms/step - loss: 0.4782 - accuracy: 0.8326 - val_loss: 0.7455 - val_accuracy: 0.7672 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "196/196 [==============================] - 93s 474ms/step - loss: 0.4399 - accuracy: 0.8462 - val_loss: 0.7129 - val_accuracy: 0.7811 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "196/196 [==============================] - 90s 461ms/step - loss: 0.4149 - accuracy: 0.8557 - val_loss: 0.5727 - val_accuracy: 0.8201 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "196/196 [==============================] - 93s 476ms/step - loss: 0.3814 - accuracy: 0.8664 - val_loss: 0.6232 - val_accuracy: 0.8083 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/196 [================>.............] - ETA: 41s - loss: 0.3543 - accuracy: 0.8738"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load test images and labels\n",
        "test_images = np.load(\"task_2_test_images.npy\")\n",
        "test_labels = np.load(\"task_2_test_labels.npy\")\n",
        "\n",
        "# Normalize pixel values of test images\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "# Convert test labels to one-hot encoded format (if needed)\n",
        "test_labels = to_categorical(test_labels, num_classes=10)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test loss: {test_loss}, Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "id": "AXIgCjn7Rcp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning"
      ],
      "metadata": {
        "id": "Qs57GMKPQeQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Load CIFAR-10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values of the images\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1KJNroiP1Md",
        "outputId": "f616ad9b-9b98-4dd3-eb9a-2f8a70458a19"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained Xception model without the top classification layer\n",
        "# Load the pre-trained Xception model without the top classification layer\n",
        "base_model = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=(71, 71, 3))\n",
        "\n",
        "# Now you can build your model on top of the Xception base model as before\n",
        "# Add your additional layers, compile the model, and define callbacks\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top of the base model\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3UHj2JvPmai",
        "outputId": "09035a02-63d9-493f-a9fd-fa0d9428f07b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, batch_size=256, epochs=100,\n",
        "                    validation_data=(x_test, y_test), callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test loss: {test_loss}, Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "U_XbNSjMP7vp",
        "outputId": "609d64db-a9f0-475d-dc4d-8392924c027e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 71, 71, 3), found shape=(None, 32, 32, 3)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9f1e76a0d737>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(x_train, y_train, batch_size=256, epochs=100,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     validation_data=(x_test, y_test), callbacks=[early_stopping, reduce_lr])\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 71, 71, 3), found shape=(None, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "id": "MoFUxgfGQQGs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}